{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opdracht - Supervised learning\n",
    "\n",
    "In deze opdracht gaan we een classificatieprobleem oplossen voor het classificeren van drie type bloemen. Het is één van de meest bekende classificatie oefeningen binnen het supervised learning gebied. Het doel van deze opdracht is om met meer dan 96% accuratie de drie type bloemen te kunnen classificeren. Om dit te bereiken hebben we een verzameling datapunten nodig met unieke eigenschappen waarmee de bloemen van elkaar gescheiden zouden kunnen worden.\n",
    "\n",
    "[Scikit-learn](https://scikit-learn.org/stable/index.html) is een populaire website/kennisbank wat veel machine learning materiaal bevat, zoals de bloemen dataset en de models waar we in deze opdracht mee gaan werken. Het onderstaande stuk code importeert de bloemen dataset. Bekijk deze data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "dataset = datasets.load_iris()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het `data` veld bevat een lijst met datapunten van de drie type bloemen. In deze lijst staan vier eigenschappen per bloem vermeld.\n",
    "\n",
    "Het `target` veld bevat een lijst van labels waarmee wordt aangetoond bij welke type bloem de data hoort. Oftewel, de vier eigenschappen van de eerste bloem `data[0]` horen bij het type bloem `target[0]`.\n",
    "\n",
    "Het veld `target_names` bevat de benamingen van de drie type bloemen.\n",
    "\n",
    "Het veld `feature_names` bevat de benamingen van de vier eigenschappen.\n",
    "\n",
    "Het onderstaande stuk code laadt deze waarden in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, target_names, feature_names = dataset.data, dataset.target, dataset.target_names, dataset.feature_names\n",
    "y_as_target_name = [target_names[target] for target in y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binnen data science is het gebruikelijk om de data (oftewel de features) waar je mee wilt werken de verzamelnaam `X` te geven, en de labels `y`.\n",
    "\n",
    "In het onderstaande stuk code kun je een tabel laten tonen waarin alle data overzichtelijk kan worden getoond. De *Pandas* module wordt o.a. hiervoor veelal gebruikt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    df = pd.DataFrame(columns=feature_names, data=X, index=y_as_target_name)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals je kunt zien hebben we te maken met de afmetingen van het bloem- en kelkblad van de setosa, versicolor en virginica bloemen. Het is nu nog altijd moeilijk te herleiden welke punten nou kenmerkend zijn voor de bloemen. De modules *Matplotlib* en *Seaborn* bieden de mogelijkheid om grafieken te visualiseren zodat je een nog beter inzicht in de data kunt verkrijgen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Numpy* is ook ingeladen. Numpy wordt gebruikt vanwege de krachtige `np.array([])` arrays die een hoop extra functionaliteit ondersteunt ten opzichte van de standaard arrays.\n",
    "\n",
    "Hieronder volgen twee functies waarmee de data in een 2D en 3D grafiek kan worden getoond. Deze functies verwachten als parameters de index waardes van de eigenschappen die je wilt tonen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training points\n",
    "def plot_2d_features(feature1, feature2):\n",
    "    with sns.color_palette(\"Set1\", n_colors=3, desat=.8) as cm:\n",
    "        plt.figure(figsize=(9, 9))\n",
    "        for i in range(len(target_names)):\n",
    "            plt.scatter(X[(i*50):(i+1)*50, feature1], X[i*50:(i+1)*50, feature2], label=target_names[i], c=[cm[i]]*50)\n",
    "        plt.xlabel(feature_names[feature1])\n",
    "        plt.ylabel(feature_names[feature2])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "def plot_3d_features(feature1, feature2, feature3):\n",
    "    with sns.color_palette(\"Set1\", n_colors=3, desat=.8) as cm:\n",
    "        fig = plt.figure(figsize=(9, 9))\n",
    "        ax = Axes3D(fig, elev=-150, azim=110)\n",
    "        for i in range(len(target_names)):\n",
    "            ax.scatter(X[(i*50):(i+1)*50, feature1], X[i*50:(i+1)*50, feature2], X[i*50:(i+1)*50, feature3],\n",
    "                       label=target_names[i], c=[cm[i]]*50, s=80)\n",
    "        ax.set_xlabel(feature_names[feature1])\n",
    "        ax.set_ylabel(feature_names[feature2])\n",
    "        ax.set_zlabel(feature_names[feature3])\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***OPDRACHT:*** *Bekijk verschillende combinaties van de features om te zien hoe ze tot elkaar verhouden.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_features(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_features(0, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals je wellicht hebt opgemerkt leiden vrijwel elke combinatie van features tot twee clusters. De setosa bloem ligt qua eigenschappen ver van de andere twee bloemen af. De uitdaging gaat dus zitten in het scheiden van de andere twee bloemen.\n",
    "\n",
    "### Jouw eerste algoritme\n",
    "\n",
    "[Scikit-learn](https://scikit-learn.org/stable/index.html) bevat [veel models](https://scikit-learn.org/stable/modules/classes.html) waarmee dit soort classificatieproblemen kan worden opgelost. In principe zou je voor dit probleem prima zelf twee simpele scheidingslijnen (`decision boundaries`) kunnen formuleren waarmee je meer dan 90% van de punten in de juiste groep kan scheiden. Dus een eenvoudig lineaire model zou daarom in theorie voldoende moeten zijn om dit probleem op te kunnen lossen.\n",
    "\n",
    "***OPDRACHT:*** *Kies een lineair model op https://scikit-learn.org/stable/modules/classes.html en pas dit toe (voel je ook vrij om voor andere soort models te gaan zoals SVM's, Neural Networks, Decision Trees, Nearest Neighbours). In de documentatie van Scikit zijn per model voorbeelden te vinden om je op weg te helpen. Gebruik de onderstaande functie om de kwaliteit van jouw algoritme te meten. Deze functie toont onder andere een `confusion matrix`. Hiermee worden de juist en onjuist geclassificeerde data getoond d.m.v. het principe true positives, true negatives, false positives, false negatives. Raadpleeg de documentatie als je meer wilt weten over de geïmporteerde functies.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix, classification_report, f1_score\n",
    "\n",
    "def show_classifier_metrics(clf, X, y):\n",
    "    ax = plot_confusion_matrix(clf, X, y, display_labels=target_names, cmap=plt.cm.Blues).ax_\n",
    "    ax.grid(False)\n",
    "    plt.show()\n",
    "    score = f1_score(y, clf.predict(X), average=\"weighted\")\n",
    "    print(f\"F1-score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jouw uitwerking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het is goed mogelijk dat jouw algoritme nu al een hogere score dan 96% heeft (of zelfs 99% als je de juiste model en parameters hebt gekozen). Aangezien de opdracht was om dit te bereiken ben je nu klaar, kun je het algoritme direct doorzetten naar productie, en roem en glorie vergaren met jouw fenomenale accurate classifier.\n",
    "\n",
    "Helaas is dit niet het geval. Eén van de grootste uitdagingen liggen in het vinden van de juiste balans van het gebruik van data waarmee het algoritme zijn netwerk zal trainen, verifiëren en uiteindelijk testen. Als het algoritme teveel data gebruikt om zijn netwerk te trainen, dan ben je het zogeheten `overfitting` principe aan het toepassen. Of `underfitting` als je te weinig data gebruikt. Het algoritme zal bij het eerste principe volledig op de traindata zijn toegespitst waardoor het ontzettend hoge scores krijgt bij het classificeren van punten die het algoritme al in het train- en verificatieproces heeft gezien. Maar zodra het nieuwe data ziet kan het algoritme er compleet naast zitten.\n",
    "\n",
    "### Overfitting bestrijden\n",
    "\n",
    "Laten we jouw bovenstaande uitwerking verbeteren door het overfitting gedeelte te elimineren. Scikit heeft een aantal handige componenten waar je dit mee kunt bereiken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_test_split` is een middel om data in twee groepen op te splitsen. `StratifiedKFold` is een middel om data in meerdere gelijke stukken op te delen waarbij de ratio van de aanwezige classes gelijk wordt gehouden (stratify).\n",
    "\n",
    "***OPDRACHT:*** *Pas `train_test_split` toe om de data (`X`) en labels (`y`) in twee groepen op te splitsen. De eerste (grotere) groep zal worden gebruikt om het algoritme mee te trainen. De tweede groep wordt exclusief gebruikt om het algoritme mee te testen (noem de data dan ook X_test en labels y_test om consistent binnen de naamconventie te blijven). Pas vervolgens `StratifiedKFold` toe om de train data op te splitsen in een train set en validatie set. Zorg ervoor dat je algoritme met de train data wordt getraind, en dat de validatie data wordt gevalideerd met de `show_classifier_metrics` functie. Gebruik de `f1_score` functie om de gemiddelde score van de train/validatie sessie te berekenen om te zien hoe goed het algoritme tijdens de validatiefase is. Meet na de train en validatie fase tot slot de kwaliteit van het algoritme door de `show_classifier_metrics` functie met de test data aan te roepen.*\n",
    "\n",
    "*Het algoritme wordt dus uiteindelijk meerdere keren met de train en validatie data getraind en gevalideerd. Als je per validatiestap bijhoudt hoe goed het algoritme presteert, dan kun je (voor een optimaal resultaat) ook het best presterende algoritme naar een variabele wegschrijven en dit algoritme bij de testfase testen. Hiervoor heb je de geïmporteerde `clone` functie nodig om een nieuwe instantie van het algoritme te creëren voor elke validatiestap, zodat bij het wegschrijven van het algoritme geen referentie wordt onthouden (en het weggeschreven algoritme dus niet bij de volgende validatiestap wordt overschreven).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jouw uitwerking\n",
    "\n",
    "# (1) opsplitsen van de data naar een train/validatie en test set\n",
    "\n",
    "# (2) opsplitsen van de train/validatie set naar train en validatie sets\n",
    "# for ... :\n",
    "\n",
    "    # (3) clone het algoritme\n",
    "    # (4) train het algoritme\n",
    "    # (5) valideer het algoritme\n",
    "    # (6) schrijf het best presterende algoritme weg naar een variabele\n",
    "    \n",
    "# (7) test het best presterende algoritme met de test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als je algoritme meer dan 96% accuratie heeft bij de test stap, goed gedaan! Zo niet, probeer dan wat parameters aan te passen (o.a. de `C` en `alpha` parameters hebben een grote invloed op de werking van het algoritme. Probeer deze aan te passen binnen het bereik 0.00001 - 10000.0) of probeer een ander Scikit model toe te passen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Een voorbeeld van hyper parameter tuning en bruteforce\n",
    "\n",
    "Soms is het lastig om te bepalen welk model of welke parameters je kan gebruiken voor het optimale resultaat. Hieronder staat een complete uitwerking van een Bruteforce methode om de juiste hyper parameters bij een aantal models te vinden.\n",
    "\n",
    "***OPDRACHT:*** *Bekijk deze code, voer het uit, voeg extra models toe en pas de code waar nodig aan in zoverre je dat wilt.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier, PassiveAggressiveClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestPerformingClassifier:\n",
    "    def __init__(self):\n",
    "        self.clf = None\n",
    "        self.score = 0.0\n",
    "        \n",
    "    def evaluate(self, clf, score):\n",
    "        if score > self.score:\n",
    "            self.clf = clf\n",
    "            self.score = score\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"{}\\nScore: {}\".format(self.clf.__str__(), self.score)\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self, clf, name):\n",
    "        self.clf = clf\n",
    "        self.name = name\n",
    "        self.scores = np.array([])\n",
    "        self.best_clf = None\n",
    "        \n",
    "    def evaluate(self, clf, score):\n",
    "        if score > self.get_max_score():\n",
    "            self.best_clf = clf\n",
    "        self.scores = np.append(self.scores, score)\n",
    "    \n",
    "    def get_max_score(self):\n",
    "        return 0.0 if len(self.scores) == 0 else np.max(self.scores)\n",
    "    \n",
    "    def get_mean_score(self):\n",
    "        return 0.0 if len(self.scores) == 0 else np.mean(self.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classifier_scores(classifiers, iterations, parameter_tuning, unique_classifiers):\n",
    "    with sns.color_palette(\"Set1\", n_colors=unique_classifiers, desat=.8) as cm:\n",
    "        plt.figure(figsize=(15, 9))\n",
    "        plt.xlabel(\"iteration\")\n",
    "        plt.ylabel(\"f1-score\")\n",
    "        r_clf = np.array([x.scores for x in classifiers]).reshape(unique_classifiers, iterations * parameter_tuning)\n",
    "        for i, classifiers_ in enumerate(classifiers.reshape(unique_classifiers, parameter_tuning)):\n",
    "            best_clf = Classifier(None, None)\n",
    "            for classifier in classifiers_:\n",
    "                if classifier.get_mean_score() > best_clf.get_mean_score():\n",
    "                    best_clf = classifier\n",
    "            plt.plot(np.arange(iterations), best_clf.scores,\n",
    "                     label=\"{0} (mean={1:.3f})\".format(best_clf.name, best_clf.get_mean_score()) , c=cm[i])\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_tuning = 10\n",
    "alpha_C_min = 1e-5\n",
    "classifiers = np.array([\n",
    "    [\n",
    "        Classifier(\n",
    "            RidgeClassifier(alpha=alpha_C_min*10**i),\n",
    "            f\"RidgeClassifier alpha={alpha_C_min*10**i}\"\n",
    "        ),\n",
    "        Classifier(\n",
    "            SGDClassifier(alpha=alpha_C_min*10**i),\n",
    "            f\"SGDClassifier alpha={alpha_C_min*10**i}\"\n",
    "        ),\n",
    "        Classifier(\n",
    "            PassiveAggressiveClassifier(C=alpha_C_min*10**i),\n",
    "            f\"PassiveAggressiveClassifier C={alpha_C_min*10**i}\"\n",
    "        ),\n",
    "        Classifier(\n",
    "            SVC(kernel=\"rbf\", C=alpha_C_min*10**i),\n",
    "            f\"SVC kernel=rbf C={alpha_C_min*10**i}\"\n",
    "        ),\n",
    "        Classifier(\n",
    "            SVC(kernel=\"linear\", C=alpha_C_min*10**i),\n",
    "            f\"SVC kernel=linear alpha={alpha_C_min*10**i}\"\n",
    "        ),\n",
    "        Classifier(\n",
    "            MLPClassifier(alpha=alpha_C_min*10**i, max_iter=10000, hidden_layer_sizes=(3,3), activation='logistic', solver='lbfgs'),\n",
    "            f\"MLPClassifier alpha={alpha_C_min*10**i}\"\n",
    "        )\n",
    "    ] for i in range(parameter_tuning)\n",
    "]).flatten('F')\n",
    "\n",
    "X_train_validation, X_test, y_train_validation, y_test = train_test_split(X, y, test_size=0.4, stratify=y)\n",
    "\n",
    "best_clf = BestPerformingClassifier()\n",
    "\n",
    "splits = 3\n",
    "best_classifiers = [BestPerformingClassifier() for i in range(splits)]\n",
    "kfold = StratifiedKFold(n_splits=splits)\n",
    "\n",
    "for iteration, (train_index, validation_index) in enumerate(kfold.split(X_train_validation, y_train_validation)):\n",
    "    print()\n",
    "    print(\"============================\")\n",
    "    print(f\"ITERATION {iteration+1}/{splits}\")\n",
    "    print(\"============================\")\n",
    "    print()\n",
    "    \n",
    "    X_train, y_train = X_train_validation[train_index], y_train_validation[train_index]\n",
    "    X_validation, y_validation = X_train_validation[validation_index], y_train_validation[validation_index]\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        clf = clone(classifier.clf)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = f1_score(y_validation, clf.predict(X_validation), average=\"weighted\")\n",
    "        classifier.evaluate(clf, score)\n",
    "        best_classifiers[iteration].evaluate(clf, score)\n",
    "    \n",
    "    print(f\"BEST CLASSIFIER: {best_classifiers[iteration]}\")\n",
    "    show_classifier_metrics(best_classifiers[iteration].clf, X_validation, y_validation)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    best_clf.evaluate(classifier.best_clf, classifier.get_mean_score())\n",
    "\n",
    "print()\n",
    "print(f\"OVERALL BEST CLASSIFIER AFTER {splits} ITERATIONS: {best_clf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classifier_scores(classifiers, splits, parameter_tuning, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classifier_metrics(best_clf.clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning\n",
    "\n",
    "***OPDRACHT***: *Probeer de iris classificatie ook eens met een model uit het unsupervised learning spectrum op te lossen. Gebruik hiervoor bijvoorbeeld KMeans. (Zie ook https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html#sphx-glr-auto-examples-cluster-plot-cluster-iris-py)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 0]\n",
      "[1 0]\n",
      "[[10.  2.]\n",
      " [ 1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "              [10, 2], [10, 4], [10, 0]])\n",
    "kmeans = KMeans(n_clusters=2).fit(X)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "print(kmeans.predict([[0, 0], [12, 3]]))\n",
    "\n",
    "print(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
